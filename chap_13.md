# 13장 : 검색어자동완성시스템

태그: 2023년 3월 2일 오후 7:48



- 사용자 입력 단어 : 자동 완성 검색어의 첫부분
- 자동완성 검색어 표시 개수 : 5개
    - 고르는 기준 : 질의 빈도에 따라 정해지는 검색어 인기 순위
- 맞춤법 검사 기능 : 불필요
- 질의 언어 : 영어 → 다국어
- DAU : 천만명
- 빠른 응답 속도

### 개략적 규모 추정

- 일간 능동 사용자 :  천만명
- 매일 10건의 검색
- 검색 마다 20바이트 데이터 입력
    - 4개 단어로 이루어짐
    - 각 단어는 다섯글자로 구성
    - 4 * 5 = 20바이트



- 초당 24,000건의 질의(QPS) 발생
    - 10,000,000 사용자 x 10 질의/일 x 20자/24시간/3600초
- 최대 QPS = QPS x 2 = 48,000
- 질의 가운데 **20%**는 **신규 검색어**
    - 10,000,000 사용자 x 10질의/일 x 20자 x 20% = 0.4GB

## 2단계, 개략적 설계안 제시 및 동의 구하기

### [1] 데이터 수집 서비스 : 사용자 입력 질의를 실시간으로 수집하는 시스템

- 질의문 - 사용 빈도 (빈도 테이블)



### [2] 질의 서비스 : 주어진 질의에 다섯개의 인기 검색어 정렬하는 시스템





⇒ 데이터가 많아진다면?

## 3단계, 상세 설계

### 트라이 자료구조

[p: prefix 의 길이 , n : 트라이 안에 있는 노드 개수, c : 주어진 노드의 자식 노드 개수]

p: prefix 의 길이 , n : 트라이 안에 있는 노드 개수, c : 주어진 노드의 자식 노드 개수

### 시간 복잡도

- O(p) + O(c) + O(clogc)
    


### ⇒ 줄여보자

- 접두어 최대 길이 제한 : O(p) → O(1)
- top5 검색어 질의 시간 복잡도 낮추기 : 노드에 인기 검색어 k개 캐시 : O(clogc) → O(1)
    - 노드에 질의어 저장 공간이 많이 필요하긴 함
    - 빠른 응답 속도가 중요할 때는 이 정도 저장공간을 희생할 만한 가치가 있음
    

    

### 데이터 수집 서비스

타이핑할 때마다 실시간으로 데이터 수정함과 동시에 트라이 갱신 비효율적

**데이터 원천과 활용을 잘 살필 필요가 있음**

만약, 트위터라면 검색어를 신선하게 유지할 필요가 있음. 하지만, 구글이라면 그렇게 자주 바꿀 필요는 없음



- **데이터 분석 서비스 로그**
    - 검색창에 입력된 질의에 관한 원본 데이터 (only create → 인덱스 NO!)

        
- 로그 취합 서버
    - 데이터 분석 서비스로부터 나온 로그를 취합하는 서버
    - 실시간성이 중요하다 : 트위터 → 데이터 취합 주기 짧게, 그이외 → 일주일에 한번?
- 취합된 데이터
    - 매주 취합한 데이터의 사례
    - time 필드는 해당 주가 시작한 날짜를 나타냄
    - frequency 필드는 해당 질의가 해당 주에 사용된 횟수의 합
        

- 작업 서버
    - 주기적으로 비동기적 작업을 실행하는 서버 집합
    - 트라이 자료구조 만들고 트라이 데이터베이스에 저장하는 역할
- 트라이 캐시
    - 분산 캐시 시스템 : 트라이 데이터를 메모리에 유지하여 읽기 연산 성능을 높임
- 트라이 데이터베이스
    1. MongoDB와 같은 Document 스타일
        1. 어차피 새 트라이를 매주 만들 것이므로 주기적으로 트라이를 직렬화하여 데이터베이스에 저장하자
    2. key-value 저장소
        1. 트라이에 보관된 모든 접두어를 해시 테이블 키로 변환
        2. 각 트라이 노드에 보관된 모든 데이터를 해시 테이블 값으로 변환
        
        해시테이블로 대응시키기
        

### 질의 서비스

트라이 캐시 확인해서 접두어에 대한 질의가 오면 캐시에 보관된 데이터를 사용해 처리하기 



1. 검색 질의가 로드밸런서로 전송된다.
2. 로드밸런서는 해당 질의를 API 서버로 보낸다
3. API서버는 트라이 캐시에서 데이터를 가져와 해당 요청에 대한 자동완성 검색어 제안 응답을 구성한다.
4. 데이터가 트라이 캐시에 없는 경우에는 데이터를 데이터베이스에서 가져와 캐시에 채운다. 그래야 다음에 같은 접두어에 대한 질의가 오면 캐시에 보관된 데이터를 사용해 처리할 수 있다. 캐시 미스는 캐시 서버의 메모리가 부족하거나 캐시 서버에 장애가 있어도 발생할 수 있다

AJAX 요청 (request) : 페이지 새로고침 안해도 됨

브라우저 캐싱 

### 트라이 연산

- 트라이 생성
- 트라이 갱신
- 검색어 삭제
    - 삭제해야 할 검색어는 자동완성 결과에서 제거해야 한다
    - DB에서 삭제하는 것보다 다음번 업데이트 사이클에 비동기적으로 삭제하자
    


### 저장소 규모 확장

- 샤딩 : 첫 글자 기준으로
    - 최대 26대 서버
    
    ⇒ 어찌되었든 각 서버에 균등하게 배분하기 어려움
    

!! 과거 질의 데이터의 패턴을 분석하여 샤딩하는 13-15 방법을 제안한다.

검색어 대응 샤드 관리자는 어떤 검색어가 어느 저장소 서버에 저장되는지에 대한 정보를 관리한다.



### 다국어 지원 가능하도록 확장하려면?

→ 트라이에 **유니코드 데이터**를 저장해야 한다.

### 국가 별로 인기 검색어 순위가 다르다면?

→ 국가별로 다른 트라이 사용. CDN에 저장하여 응답 속도 높이기

### 실시간으로 변하는 검색어의 추이를 반영하려면 ?

→ 일단 본 설계안은 작업 서버가 매주 한 번씩만 돌도록 되어 있어서 시의 적절하게 트라이를 갱신하기 어려움

→ 트라이를 구성하는데 너무 많은 시간이 소요됨

- 샤딩을 통해 작업 대상 데이터의 양을 줄인다
- 순위 모델을 바꾸어 최근 검색어에 보다 높은 가중치를 주도록 한다.
- 데이터가 스트림 형태로 와서 동시에 사용할 수 없을 가능성이 있다는 점을 고려해야 한다. 스트림 프로세싱에는 특별한 종류의 시스템이 필요하다.