# 대규모 1~3장

발표자: 기윤 권, 김윤우
생성 일시: 2023년 5월 9일 오후 11:02
태그: 질문

## 궁금해요

### 1장 @기윤 권

- p.5 다루는 데이터가 비정형이라 관계형 데이터가 아님
  > **비정형 데이터란 무엇인가요? (비교해서 개념 설명 부탁드립니다.) @박은정**
  ***
  - 식별 가능한 구조나 아키텍처가 없는 데이터
  비정형 데이터 예시 )
  1. 텍스트 문서
  2. 이미지
  3. 오디오 및 음악
  4. 비디오
  5. 소셜 미디어 데이터
  6. 로그 파일
- p.5 비 관계형 데이터베이스는 일반적으로 조인 연산은 지원하지 않는다.
  > **관계형 데이터베이스와 다른 어떤 점이 있길래 비 관계형 데이터베이스는 조인 연산을 지원하지 않는 거죠? 더 자세한 설명이 필요합니다. @박은정**
  ***
  NoSQL데이터베이스는 **수평적으로 분산되고 확장되도록 설계**되었기 때문에, 복잡한 조인 대신 고성능 읽기 및 쓰기 작업을 우선시합니다.
  조인 작업과 비슷한 결과를 얻기 위해 (1) 비정규화(Denormalization) (2) 애플리케이션 상 조인(Application-side Joins) (3) MapReduce 연산 지원 (4) Graph Database 와 같은 방법을 제안합니다.
  **(1) 비정규화(Denormalization)**
  동일한 document나 collection에 관련있는 데이터를 모아 저장한다. 이로 인해 읽기 성능이 향상될 수 있지만, data redundancy나 update 복잡성을 증가 시킬수 있다.
  **(2) 애플리케이션 상 조인 (Application-Side Joins)**
  application code 내에서 join 연산을 수행한다. 이 방식은 application layer에서 추가적인 연산이 필요하기에 대용량 데이터셋을 처리하는 경우 성능에 영향을 끼칠 수 있다.
  **(3) MapReduce 연산 지원**
  MongoDB와 같은 몇몇의 NoSQL Database는 MapReduce 연산을 지원한다. MapReduce 연산은 cluster of machine에서 데이터를 **mapping(매핑) 하고 reducing(축소)하여 복잡한 데이터 처리 작업**을 수행할 수 있다. MapReduce는 조인과 유사한 결과를 달성하는 데 도움이 될 수 있지만, 수동 작업이 더 많이 필요하며 특정 사용사례에 적합하다.
  **(4) Graph database**
  그래프와 유사한 데이터 구조를 관리하고 쿼리하는데 탁월하므로 관계를 효율적으로 탐색할 수 있다.
- **[면접질문] NoSQL 종류 ?**
  1. key-value
  2. column based database : column 별로 따로 저장되어있음

     **_Cassandra_** (카산드라)

     장점 : 서비스 중, column 별로 특정 데이터를 빠르게 읽기,쓰기하기 위해

     단점 : SQL처럼 “select \* from table” 를 지원하지 않는다.

  3. document

     MongoDB (몽고디비)

     이용자별 트윗, 좋아요한 트윗

  4. graph database
  5. Google Big Query
- p.5 아주 많은 양의 데이터를 저장할 필요가 있음
  > **비 관계형 데이터베이스에 많은 양의 데이터를 저장하는 것이 (비교적) 효과적인 이유는 무엇인지 비 관계형 데이터베이스의 특징과 연관해서 설명해주세요 @박은정**
  ***
  - **비 관계형 데이터베이스의 특징**
    1. **스케일 아웃 및 가용성**
    비 관계형 데이터베이스는 수평적으로 확장가능한 아키텍처를 갖추고 있다. 데이터베이스를 여러 노드로 분산하여 처리 능력을 확장할 수 있고, 높은 가용성을 제공할 수 있다.
    1. **유연한 데이터 모델**
    비 관계형 데이터베이스는 스키마가 유연하며 데이터 모델을 자유롭게 정의할 수 있다. 따라서, 데이터 모델의 변경이나 스키마 업데이트에 따른 중단이나 데이터 마이그레이션의 부담이 줄어든다.
    1. **분산 데이터 저장**
    데이터의 로드 밸런싱과 병렬 처리를 통해 높은 성능을 제공한다.
    1. **높은 읽기/쓰기 처리량**
    **데이터를 수평적으로 분산 저장**하므로 읽기 및 쓰기 작업을 병렬로 처리할 수 있다. 이는 대량의 데이터에 대한 처리량과 처리 성능을 향상시키는 데 도움을 준다.
    1. **다양한 데이터 유형 지원**
    비정형 데이터를 효과적으로 저장하고 처리할 수 있다.
  **→ 대규모 데이터 처리, 실시간 분석, 빅데이터 환경 등에서 활용된다.**
  - [추가] **ElasticSearch : 비 관계형 분산 검색 및 분석 엔진**
    **1. 분산 아키텍처**
    **2. 실시간 검색 및 분석** : 실시간으로 데이터를 색인하고, 복잡한 질의를 통해 데이터를 빠르게 검색할 수 있다. 또한, 다양한 분석 작업을 지원하며 Kibana와 같은 도구를 사용하여 데이터 시각화와 함께 실시간 대시보드를 생성할 수 있다.
    **3. 스키마 없는 데이터 모델** : 필드 및 데이터 형식을 동적으로 매핑하여 데이터를 색인한다. 이는 새로운 데이터 형식을 쉽게 수용할 수 있도록 한다.
    **4. 다양한 검색 기능**
  - **ElasticSearch의 데이터 색인 과정**
    Elasticsearch는 데이터를 검색 및 분석하기 위해 **역색인(inverted index)**이라고 알려진 특정한 데이터 구조를 사용하여 색인합니다. 역색인은 효율적인 풀 텍스트 검색을 위해 텍스트 데이터를 단어 레벨로 분리하고, 각 단어가 어떤 문서에 존재하는지를 기록하는 역방향 매핑입니다. 이를 통해 Elasticsearch는 쿼리 시간에 빠르게 문서를 검색할 수 있습니다.
    [6.1 역 인덱스 - Inverted Index](https://esbook.kimjmin.net/06-text-analysis/6.1-indexing-data)
    ***
    1. 문서 준비: Elasticsearch에 색인할 데이터를 문서 단위로 준비합니다. 문서는 JSON 형식으로 구성되며, 필드와 해당 값으로 구성됩니다. 예를 들어, 제목(title), 내용(content), 작성자(author) 등의 필드가 있을 수 있습니다.
    2. 문서 색인: Elasticsearch는 문서를 인덱스(index)에 저장합니다. 인덱스는 관련된 문서 집합을 그룹화하는 논리적인 컨테이너입니다. 예를 들어, "blog" 인덱스는 블로그 게시물을 포함하는 컨테이너일 수 있습니다. 각 인덱스는 여러 개의 샤드(shard)로 분할되어 분산 저장됩니다.
    3. 토큰화: 문서의 텍스트 필드는 토큰화 과정을 거칩니다. 토큰화는 문서의 텍스트를 단어로 분할하는 과정입니다. 일반적으로 공백이나 구두점을 기준으로 단어를 분리합니다. 예를 들어, "Hello, world!"라는 문장은 "Hello"와 "world"라는 두 개의 단어로 분리될 수 있습니다.
    4. 역색인 생성: 토큰화된 단어는 역색인 구조에 매핑됩니다. 역색인은 단어와 해당 단어가 등장하는 문서의 매핑을 가지고 있습니다. 단어는 색인 구조 안에서 고유한 식별자인 용어(term)로 관리됩니다. 각 용어는 역색인에서 문서 식별자(document ID)와 함께 저장됩니다.
    5. 검색: 역색인이 생성되면 Elasticsearch는 사용자의 검색 요청을 처리합니다. 사용자가 특정 단어 또는 구문으로 검색을 수행하면 Elasticsearch는 해당 검색어에 대해 역색인을 조회하고 관련된 문서를 신속하게 찾아냅니다.
    6. 결과 반환: Elasticsearch는 검색 결과를 반환합니다. 이는 관련 문서의 순위(정확도)에 따라 정렬된 문서의 목록으로 제공됩니다. 또한, 검색 쿼리에 따라 필터링, 집계, 하이라이팅 등의 추가 기능을 제공할 수 있습니다. 검색 결과는 JSON 형식으로 반환되며, 클라이언트 애플리케이션에서 이를 처리하고 표시할 수 있습니다.
    7. 업데이트 관리: Elasticsearch는 색인된 문서의 업데이트를 지원합니다. 기존에 색인된 문서를 업데이트하거나 새로운 문서를 추가할 수 있습니다. 업데이트는 새로운 문서로 대체되는 것이 아니라 문서의 일부 필드만 업데이트할 수 있습니다. Elasticsearch는 업데이트된 문서를 기존 문서와 병합하여 역색인을 업데이트합니다.
    8. 색인 최적화: Elasticsearch는 데이터의 색인을 최적화하는 작업을 수행합니다. 이를 통해 검색 성능을 향상시키고 디스크 공간을 절약할 수 있습니다. 색인 최적화는 삭제된 문서를 정리하거나 새로운 샤드를 생성하여 데이터의 균형을 맞추는 등의 작업을 수행합니다.
    9. 클러스터 및 복제: Elasticsearch는 여러 노드로 구성된 클러스터에서 작동할 수 있습니다. 클러스터에는 여러 개의 복제본(replica)이 있을 수 있으며, 이는 데이터의 가용성과 내결함성을 제공합니다. 데이터는 여러 복제본에 분산되어 저장되며, 복제본 간에 동기화가 유지되어 데이터의 안정성과 고가용성이 보장됩니다.
- p.5 수직적 규모 확장법은 장애에 대한 자동복구(failover) 방안이나 다중화 방안을 제시하지 않는다.
  > 장애에 대한 자동복구(failover) 방안, 다중화(redundancy) 방안에 대해서 조사해서 알려주세요
  > 그리고, 이것이 왜 필요한지 설명해주세요
  ***
  - failover 가 무엇인가요?
    자동 복구는 시스템의 중요한 구성 요소가 **장애가 발생하면 자동으로 대체**되어 **시스템의 가용성과 연속성을 유지하는 방법**입니다.
    일반적으로는 여러 개의 시스템 또는 서버를 구성하고, 하나의 시스템이 장애가 발생하면 **나머지 시스템이 자동으로 해당 기능을 대신하도록 설정**됩니다. 이를 위해 장애 감지, 장애 발생 시 대체 시스템으로의 자동 전환, 그리고 사용자 트래픽을 대체 시스템으로 이동시키는 등의 기능이 포함될 수 있습니다.
  - **failover 방식에는 무엇이 있나요?**
    - **Active-Passive Failover**
      Active-Passive Failover는 주 서버와 대기 서버(패시브 서버)로 구성됩니다. 주 서버가 정상적으로 작동하는 동안에는 대기 서버는 대기 상태에 있습니다. **주 서버에 장애가 발생하면 대기 서버가 활성화되어 주 서버의 역할을 수행**합니다. 이 방식은 비용을 줄이고 구성이 단순하며, 대기 서버는 주 서버의 동기화된 복사본을 유지함으로써 **데이터 일관성을 유지**합니다.
    - **Active-Active Failover**
      Active-Active Failover는 **여러 개의 활성 서버로 구성**됩니다. 모든 서버가 동시에 작동하며, **장애가 발생하면 트래픽이 다른 활성 서버로 분산**됩니다. 이 방식은 부하 분산과 성능 향상을 위해 사용됩니다. 각 서버는 독립적인 작업을 수행하고 데이터를 동기화하여 일관성을 유지합니다.
    - **N+1 Failover**
      N+1 Failover는 **N개의 작동 중인 서버와 여분의 대기 서버**로 구성됩니다. 주 서버 중 하나에 장애가 발생하면 **대기 서버가 해당 서버를 대체**합니다. 이 방식은 스케일 아웃 구조에서 많이 사용되며, 장애 발생 시 서비스의 중단 없이 트래픽을 처리할 수 있습니다.
    - **Cloud-based Failover**
      클라우드 기반의 Failover는 서비스를 **클라우드 환경으로 이전**하여 장애 발생 시 자동으로 다른 지역 또는 클라우드 인프라로 전환합니다. 클라우드 제공 업체는 **다중 지역에 걸쳐 여러 데이터 센터를 운영**하므로, **한 지역에서의 장애로부터 서비스를 보호**할 수 있습니다.
    - **데이터베이스 복제**
      데이터베이스 복제는 데이터베이스 시스템에 대한 Failover를 제공하는 방법 중 하나입니다. 주 데이터베이스 서버와 여러 복제본이 있으며, 주 서버에 장애가 발생하면 하나의 복제본이 주 서버의 역할을 수행합니다. 데이터베이스 복제는 데이터 일관성과 내구성을 보장해주는데, 일반적으로 동기 복제와 비동기 복제 두 가지 방식이 있습니다.
      - **동기 복제(Synchronous Replication):** 동기 복제는 주 데이터베이스 서버에 데이터 변경이 발생하면 해당 변경 사항을 복제 서버에 즉시 전달하는 방식입니다. 주 서버에 트랜잭션을 완료하기 전까지는 복제 서버에 대한 응답이 이루어지지 않습니다. 이를 통해 데이터의 일관성과 안정성을 보장할 수 있습니다. 그러나 동기 복제는 네트워크 지연이나 복제 서버의 장애로 인해 응답 시간이 지연될 수 있으며, 주 서버의 성능에도 영향을 줄 수 있습니다.
      - **비동기 복제(Asynchronous Replication):** 비동기 복제는 주 데이터베이스 서버에 데이터 변경이 발생하면 해당 변경 사항을 복제 서버로 비동기적으로 전송하는 방식입니다. 주 서버의 트랜잭션이 완료된 후에 복제가 이루어지므로, 응답 시간이 빠르고 주 서버의 성능에 영향을 덜 주지만, 데이터의 일관성이 약간 떨어질 수 있습니다. 데이터의 손실 가능성이 존재할 수 있으므로 장애 시 일부 데이터의 손실을 감수해야 할 수도 있습니다.
    위에서 언급한 방법 외에도 **로드 밸런서, 가상 IP(Virtual IP) 기반의 Failover**, 그리고 **클러스터링** 등의 다른 방식을 사용하여 Failover를 구현할 수도 있습니다.
  - redundancy 개념
    다중화는 시스템의 중요한 구성 요소를 중복해서 구성함으로써 장애 발생 시에도 **서비스의 지속성을 확보하는 방법**입니다. 예를 들어, 여러 개의 서버를 병렬로 운영하여 하나의 서버에 장애가 발생하면 **다른 서버가 그 역할을 대신 수행**하도록 구성합니다. 또는 데이터베이스의 경우, 데이터를 여러 개의 서버에 복제하여 **하나의 서버에 장애가 발생하더라도 데이터의 안정성을 유지할 수 있도록** 합니다.
- p.6 웹 서버가 한계 상황에 도달하게 되면 응답 속도가 느려지거나 서버 접속이 불가능해질 수도 있다. 이를 방지/관리하는 방안에 대해 조사해서 설명해주세요 @박은정
  ***
  1. 로드 밸런싱
  2. 캐싱
  3. 성능 최적화
     1. 동시 연결 수
     2. 스레드 풀 크기 조절 (미리 생성된 스레드의 풀을 유지하여 동시에 처리할 수 있는 요청의 수)
- p.7 데이터베이스 다중화 / p.20 데이터 센터
  (큰일이 났던) 카카오 예시를 조사해서 다중화의 중요성에 대해 알려주세요
  자동화된 배포 도구는 모든 데이터 센터에 동일한 서비스가 설치되도록 하는 데 중요한 역할을 한다.
  ***
  [if(kakao) dev 2022](https://www.notion.so/if-kakao-dev-2022-db8eb550fb3b44e18c1cb243b8a497b7?pvs=21)
- **[면접 예상질문] 메시지 큐를 왜 사용하였나요?**
  A. 시스템의 컴포넌트를 분리하여, 각기 독립적으로 확장될 수 있도록 하기 위해서 입니다.
  생산자는 소비자 프로세스가 다운되어 있어도 메시지를 발행할 수 있고, 소비자는 생산자 서비스가 가용한 상태가 아니더라도 메시지를 수신할 수 있습니다.
  - **메시지 큐의 특징에 대해 설명해주세요**
    메시지 큐에 보관된 메시지는 소비자가 꺼낼 때까지 안전하게 보관됩니다.
    메시지의 버퍼 역할을 하여 비동기적으로 전송합니다.
  - **기본 아키텍처에 대해 설명해주세요**
    메시지 큐는 Producer 라 불리는 입력서비스가 메시지를 메시지 큐에 발행(publish) 합니다. 큐에는 소비자 혹은 구독자(Consumer)라 불리는 서버가 연결되어있는데 메시지를 받아 그에 맞는 동작을 수행하는 역할을 합니다.
  - **예를 들어 설명해주세요**
    시간이 많이 걸리는 cropping, sharpening, blurring을 지원하는 사진 보정 애플리케이션은 비동기적으로 처리하면 편리합니다. 웹 서버는 사진 보정 작업을 메시지 큐에 넣고, 사진 보정 작업 프로세스들은 이 작업을 메시지 큐에서 꺼내어 비동기적으로 완료합니다.
    - **큐의 크기와 작업 프로세스 수의 상관관계에 대해 설명해주세요**
      큐의 크기가 커지면, 더 많은 작업 프로세스를 추가해야 처리 시간을 줄일 수 있습니다. 하지만, 큐가 거의 항상 비어있는 상태라면, 작업 프로세스의 수를 줄일 수 있습니다.
- p.9 부 서버에 보관된 데이터가 최신 상태가 아닐 수 … 복구 스크립트(recovery script)를 돌려서 추가해야 한다. 다중 마스터(multi-masters)나 원형 다중화(circular replication) 방식을 도입..
  복구 스크립트,, 다중 마스터,, 원형 다중화 방식 에 대해서 자세한 설명 부탁드립니다.
  그.. 구글에 DB 복구 관련해서 쳤었는데 찾아도 안나와서..
  [Multi-master replication](https://en.wikipedia.org/wiki/Multi-master_replication)
  [](https://dev.mysql.com/doc/refman/5.7/en/mysql-cluster-replication-multi-master.html)
  ![Untitled](notes/%E1%84%83%E1%85%A2%E1%84%80%E1%85%B2%E1%84%86%E1%85%A9%201~3%E1%84%8C%E1%85%A1%E1%86%BC%20a0f1103cc60c446dad23983674cb81e2/Untitled.png)
  ![Untitled](notes/%E1%84%83%E1%85%A2%E1%84%80%E1%85%B2%E1%84%86%E1%85%A9%201~3%E1%84%8C%E1%85%A1%E1%86%BC%20a0f1103cc60c446dad23983674cb81e2/Untitled%201.png)
  [다중 마스터 복제 (Sun Java Enterprise System 2005Q4 배포 계획 설명서)](https://docs.oracle.com/cd/E19636-01/819-3452/aavfg/index.html)

---

- p.11 읽기 주도형 캐시 전략(read-through caching strategy)라고 부른다. 이것 이외에도 다양한 캐시 전략이 있다. 캐시할 데이터 종류, 크기, 액세스 페턴에 맞는 캐시 전략을 선택하면 된다.
  다양한 캐시 전략에 대해 나열하고, 캐시 전략을 선택하는 기준에 대해 설명해주세요
  [[REDIS] 📚 캐시(Cache) 설계 전략 지침 💯 총정리](https://inpa.tistory.com/entry/REDIS-📚-캐시Cache-설계-전략-지침-총정리)
  ***
- **p12. 캐시에 보관된 데이터는 어떻게 만료(expire)되는가?**
  > 적절한 캐시 만료 기간은 어떻게 정하나요?? @김윤우
  ***
  적절한 만료기간을 결정하기 위해서는 다음과 같은 요소들을 고려해야 합니다.
  1. 데이터 갱신 빈도
     - 데이터가 자주 갱신된다면 적절한 만료기간을 짧게 설정해야 합니다.
     - 예를 들어, 주식 가격 정보는 실시간으로 변동되기 때문에 만료 기간을 짧게 설정하는 것이 적절합니다.
  2. 데이터의 중요도
     - 데이터가 중요하다면 만료기간을 짧게 설정하여 최신 정보를 제공해야 합니다.
     - 예를 들어, 사용자의 개인 정보와 같은 중요한 데이터는 만료기간을 짧게 설정하는 것이 좋습니다.
  3. 데이터 크기
     - 큰 데이터일수록 캐시를 사용하는 것이 유리합니다. 하지만 만료기간을 너무 길게 설정하면 오래된 데이터가 계속해서 저장되어 캐시 메모리를 차지할 수 있습니다.
  4. 사용자 행동 패턴
     - 사용자들이 자주 사용하는 데이터라면 만료기간을 길게 설정해도 좋습니다.
     - 예를 들어, 사용자의 프로필 정보와 같은 데이터는 자주 변경되지 않기 때문에 만료기간을 길게 설정하는 것이 적절합니다.
  5. 캐시 메모리 크기
     - 캐시 메모리의 크기에 따라 만료기간을 설정해야 합니다.
     - 캐시 메모리가 크다면 만료기간을 길게 설정해도 됩니다.
  이러한 요소들을 고려하여 적절한 만료기간을 설정하면 캐시를 효과적으로 사용할 수 있습니다.
- **[면접 예상질문] p.18 고정 세션 → 공유 저장소**
  [Sticky Session](https://kchanguk.tistory.com/146)
  [다중 서버 환경에서 Session은 어떻게 공유하고 관리할까? - 2편(Sticky Session, Session Clustering, Session Storage 분리)](https://hyuntaeknote.tistory.com/6)

---

- p.23 큐의 크기가 커지면… 있을 것이다. → 이해가 안돼요
  생산자 → 메시지 큐 → 소비자 관계에서
  메시지 큐는 메시지의 버퍼 역할을 함
  버퍼니까 메시지 큐의 크기가 크다 → 버퍼의 크기가 크다
  → 적은 작업 프로세스의 메시지로는 버퍼를 채우는데 시간이 오래 걸린다
  → 많은 작업 프로세스라면 적은 것에 비해서 버퍼를 채우는데 시간이 적게 걸린다
- p.23 로그, 메트릭
  현업에서 자주 쓰이는 로그, 메트릭 툴을 조사해주세요
  - 로그
    - 실무에서는 Logback 많이 쓴다함
    - logback
    ### **Faster implementation**
    LogBack은 새롭게 작성된 것이 아니라 오랫동안 검증된 Log4j의 아키텍처를 기반으로 재작성 되었습니다.
    다만, 강조하는 점은 성능은 약 10배 정도 개선되었고, 설치 메모리 공간은 더 적게 사용한다고 합니다.
    ### **Extensive batterty of tests**
    LogBack은 Log4j2와 같은 개발자가 만들었습니다. 따라서 log4j를 통해 얻은 많은 테스트 자료들이 있습니다. 그것이 Log4j보다 더 뛰어난 것을 만들 수 있는 기반이 되었습니다.
    ### **Automatic reloading of configuration files**
    LogBack을 사용하는 이유가 되는 기능 중 하나입니다.
    하나의 예로 운영서버에서는 로그레벨을 WARN 또는 ERROR로 하는게 보통입니다.
    하지만 특정 부분에서 더 자세한 로그를 봐야할 필요성이 있다면 INFO로 바꾸게 됩니다.
    이때 log4j는 서버를 '셧다운'하고 '재설정'을 한 다음 '서버기동'을 해야합니다.
    즉, 서버를 다시 '재기동'해야 한다는 번거러움이 있는데, LogBack은 그러지 않아도 됩니다.
    그 이유는 내부를 스캐닝하는 별도의 스레드가 알아서 로그 레벨을 바꿔서 알려주기 때문입니다.
    하지만, '이러한 추가적인 스레드를 운용하면 메모리 자원을 서비스를 하는 것을 희생해서 가져다 쓰는 것이 아닌가?'
    하는 의문이 들 수 있습니다.
    이러한 의문에 대한 답을 LogBack은 다시 적절하게 대처하고 있습니다.
    공식문서를 보면 이러한 스레드를 '스캐닝 스레드'라고 부르고 이것은 메모리에 대한 점유율을 최소화하고
    그 예로 '100개의 스레드가 초장 백만번 호출을 해도 시스템에 눈에 띄는 무리를 주지 않는다' 라고 답합니다.
    ### **Graceful recovery from I/O failures**
    LogBack은 FileAppender와 RollingFileAppender를 포함한 모든 하위 클래스는 I/O 장애로부터 정상적으로 복구할 수 있습니다. 따라서 파일 서버가 일시적으로 실패할 경우, 로그를 다시 실행하기 위해 프로그램을 다시 시작할 필요가 없습니다.
    ### **Automatic removal of old log archives**
    아카이빙 된 파일은 서비스를 지속하게 되면 계속 쌓이게 됩니다. 이러한 파일은 처음에 별로 양이 많지 않을 때는 괜찮겠지만 점점 쌓이게 되면 결국 자원 낭비로 이어질 것입니다.
    이 부분을 해결하기 위해 LogBack은 일정 기간이 지나면 서비스에 부담을 주지 않기 위해 파일을 삭제할 것입니다.
    ### **Prudent mode**
    하나의 서버에서 다수의 JVM이 기동중일 경우 하나의 파일에 로그를 수집하려고 할 때 사용하는 기능입니다.
    이 기능을 통해 멀티 스레드인 상황에서 LogBack을 사용하여 효율적으로 처리하게 됩니다.
  - 메트릭
    - 이건 검색해도 안나오네
    - **프로메테우스 - 오픈소스**
    [프로메테우스(Prometheus) 알아보기](https://cumulus.tistory.com/86)
  ***

### 2장 @김윤우

[2장 정리](notes/%E1%84%83%E1%85%A2%E1%84%80%E1%85%B2%E1%84%86%E1%85%A9%201~3%E1%84%8C%E1%85%A1%E1%86%BC%20a0f1103cc60c446dad23983674cb81e2/2%E1%84%8C%E1%85%A1%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%203fb7f4af729d46c58dee1a130bb49d86.md)

- p.36 트위터 QPS와 저장소 요구량 측정
  공식(?), 개념들 잘 정리해주세요 미리 ㄳ (뒷장에서 이 기준이 중요해요)
  QPS, 최대 QPS, 저장소 요구량, 캐시 요구량, 서버 수
  ***
  - chat gpt 왈..
    서버 개발자는 QPS(Queries Per Second), DAU(Daily Active Users) 및 피크 QPS(Peak Queries Per Second)와 같은 메트릭에 익숙해야 합니다. 이러한 메트릭은 서버 시스템의 성능 및 확장성 요구 사항에 대한 귀중한 통찰력을 제공하기 때문입니다. 이러한 각 측정항목이 중요한 이유는 다음과 같습니다.
    1. QPS(초당 쿼리 수): QPS는 서버 시스템이 1초 내에 받는 쿼리 또는 요청 수를 측정합니다. 서버 개발자가 서버의 로드를 이해하고 들어오는 요청을 처리할 수 있는 용량을 평가하는 데 도움이 됩니다. 개발자는 QPS를 모니터링하여 서버가 예상되는 트래픽 볼륨을 처리할 수 있는지 여부와 원활한 작동을 위해 최적화 또는 추가 리소스가 필요한지 여부를 결정할 수 있습니다.
    2. DAU(Daily Active Users): DAU는 매일 서버 시스템과 상호 작용하는 순 사용자 수를 나타냅니다. 서버 개발자는 사용자 기반 및 잠재적인 동시 연결에 대한 추정치를 제공하므로 DAU를 고려해야 합니다. 용량 계획, 리소스 할당 및 예상 사용자 수를 수용하기 위한 서버 인프라 확장에 도움이 됩니다. DAU를 알면 개발자는 최대 사용 기간 동안 서버가 예상되는 부하를 처리할 수 있는지 확인할 수 있습니다.
    3. 피크 QPS(Peak Queries Per Second): 피크 QPS는 서버 시스템이 가장 바쁜 기간 동안 1초 이내에 받는 쿼리 또는 요청의 최대 수를 나타냅니다. 서버 개발자가 최대 QPS를 식별하여 서버가 처리해야 하는 최대 로드를 결정하는 것이 중요합니다. 피크 QPS를 이해함으로써 개발자는 서버 아키텍처를 설계 및 최적화하고, 캐싱 전략을 구현하고, 인프라를 확장하여 성능 저하 없이 트래픽이 많은 기간의 요구 사항을 충족할 수 있습니다.

### 3장 @김윤우

[3장 정리: 시스템 설계 면접 공략법](notes/%E1%84%83%E1%85%A2%E1%84%80%E1%85%B2%E1%84%86%E1%85%A9%201~3%E1%84%8C%E1%85%A1%E1%86%BC%20a0f1103cc60c446dad23983674cb81e2/3%E1%84%8C%E1%85%A1%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20%E1%84%89%E1%85%B5%E1%84%89%E1%85%B3%E1%84%90%E1%85%A6%E1%86%B7%20%E1%84%89%E1%85%A5%E1%86%AF%E1%84%80%E1%85%A8%20%E1%84%86%E1%85%A7%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B8%20%E1%84%80%E1%85%A9%E1%86%BC%E1%84%85%E1%85%A3%E1%86%A8%E1%84%87%E1%85%A5%E1%86%B8%20afc16361baf74b00807dd42c96b658a5.md)

- p.41 효과적 면접을 위한 4단계 접근 방법
  잘 정리해서 설명해주세요. 뒷 부분에서 계속 형식이 반복됩니다.
  ***
- p.44 피드 발행과 피드 생성
  ( 책 내용에서 ) 두 단어가 무엇을 의미하는지
  ***
- p.45 그림3-1
  포스팅 캐시의 역할, 왜 필요한지

---
