# 6장 정리 노트

[https://velog.io/@kyy00n/대규모-시스템-설계-기초-6장.-키-값-저장소-설계](https://velog.io/@kyy00n/%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%A4%EA%B3%84-%EA%B8%B0%EC%B4%88-6%EC%9E%A5.-%ED%82%A4-%EA%B0%92-%EC%A0%80%EC%9E%A5%EC%86%8C-%EC%84%A4%EA%B3%84)

# 키-값 저장소(key-value store) 설계

- 용어
    - **키-값 저장소**: **비 관계형(non-relational) DB**
    - **키**: 고유 식별자
    - **키-값 쌍(pair)**: 키와 값 사이의 연결 관계
- 특징
    - 키는 유일해야 함
    - 값은 키를 통해서만 접근 가능
    - 키는 일반 텍스트 or 해시값
    - 키는 짧을 수록 좋음(성능 이슈)
    - 값은 문자열 or 리스트 or 객체. 뭐가 오든 상관 X
    - ex) 아마존 다이나모, memcached, 레디스 등이 있다.
    - `put(key, value)`: 키-값 쌍을 저장소에 저장한다.
    - `get(key)`: 인자로 주어진 키에 메달린 값을 꺼낸다.

---

### 문제 이해 및 설계 범위 확정

- 설계 팁
    - 읽기, 쓰기, 메모리 사용량 사이의 어떤 균형을 찾자
    - 데이터의 일관성(consistency)과 가용성(availability) 사이에 타협적 결정을 내리자

---

### 단일 서버 키-값 저장소

- 키-값 쌍 전부를 메모리에 해시 테이블로 저장
- 빠른 속도, but 모든 데이터를 메모리 안에 두는 것이 불가능 할 수도 있음
- 개선책
    - 데이터 압축
    - 자주쓰는 데이터만 메모리, 나머지 디스크에 저장
- 많은 데이터를 저장하려면 분산 **키-값 저장소(distributed key-value store)**를 만들 필요가 있음

---

### 분산 키-값 저장소(분산 해시 테이블)

- 키-값 쌍을 여러 서버에 분산 시킴
- CAP 정리(Consistency, Availability, Partition Tolerance theorem)
    
    ### **데이터 일관성, 가용성, 파티션 감내라는 세가지 요구사항을 동시에 만족하는 분산 시스템을 설계하는 것은 불가능하다는 정리**
    
    - 각 요구사항의 의미
        - 데이터 일관성: 분산 시스템에 접속하는 모든 클라이언트는 **어떤 노드에 접속했느냐와 관계없이** 언제나 같은 데이터를 보게 되어야 한다.
        - 가용성: 분산 시스템에 접속하는 클라이언트는 **일부 노드에 장애가 발생**하더라도 **항상 응답**을 받을 수 있어야 한다.
        - 파티션 감내: **파티션**은 **두 노드 사이에 통신 장애**가 발생하였음을 의미. 파티션 감내는 **네트워크에 파티션이 생기더라도 시스템은 계속 동작**하여야 한다
        - 즉 2가지 충족하려면 나머지 하나는 희생
    
    ![Untitled](6%E1%84%8C%E1%85%A1%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20%E1%84%82%E1%85%A9%E1%84%90%E1%85%B3%20adbfe6682f0042a99c74d7c6ea0d1b4d/Untitled.png)
    
    통상 네트워크 장애는 피할 수 없기 때문에 반드시 파티션 문제를 감내할 수 있도록 설계 → CA시스템은 존재X
    
    ![Untitled](6%E1%84%8C%E1%85%A1%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20%E1%84%82%E1%85%A9%E1%84%90%E1%85%B3%20adbfe6682f0042a99c74d7c6ea0d1b4d/Untitled%201.png)
    
    - 일관성을 만족 → CP
        - 세 노드 사이의 데이터 불일치 문제를 피하기 위해 쓰기 연산 중단(가용성 깨짐)
    - 가용성을 만족 → AP
        - 계속 읽기 연산 허용(낡은 데이터를 반환하더라도)
        - 쓰기도 허용. 문제 해결 후 새 데이터 n3에 전송
    - 분산 키-값 저장소를 만들 때는 그 요구사항에 맞도록 CAP 정리를 적용해야한다.
    - 면접관과 상의, 그 결론에 따라 시스템 설계하자
    
- 시스템 컴포넌트(핵심 컴포넌트 및 기술들)
    - 데이터 파티션
        
        데이터를 작은 파티션으로 분할한 다음 여러 대의 서버에 저장
        
        - 고려해야할점
            - 데이터를 여러 서버에 고르게 분산할 수 있는가?
            - 노드가 추가되거나 삭제될 때 데이터의 이동 최소화할 수 있는가?
        - 안정 해시를 사용한 데이터 파티션
            - 규모 확장 자동화(automatic scaling): 서버 자동 추가 및 삭제
            - 다양성: 서버 용량에 맞게 가상노드 수 조정 가능
    - 데이터 다중화
        
        높은 가용성과 안정성을 확보하기 위함
        
        `키를 링 위에 배치한 후, 시계 방향으로 순회하면서 만나는 첫 N개 서버에 데이터 사본 보관`
        
        - 가상 노드를 사용한다면 물리 서버를 중복 선택하지 않도록 해야
    - 데이터 일관성
        - 다중화된 데이터는 적절히 동기화 되어야 함
        - 정족수 합의(Quorum Consensus) 프로토콜
            - N: 사본 개수
            - W: 쓰기 연산에 대한 정족수. 즉 쓰기 연산 성공 = **최소** W개 서버에서 쓰기 연산이 성공
            - R: 읽기 연산에 대한 정족수:  **최소** R개 서버로부터의 응답필요
            - 중재자(coordinator): 클라이언트와 노드 사이의 프록시(proxy) 역할
            - W, R, N의 값을 정하는 것은 응답 지연과 데이터 일관성 사이의 타협점을 찾는 전형적인 과정
                - W,R 값이 작으면 응답속도는 빠름. 크면 응답속도는 느려지겠지만 일관성 수준은 향상됨.
                - W+R>N 인 경우 강한 일관성 보장.
            - 요구되는 일관성 수준에 따라 값을 조정할 것
    - 일관성 모델 종류
        - 강한 일관성: 모든 읽기 연산은 최신 갱신된 결과 반환을 보장
        - 약한 일관성: 최근 갱신된 결과 반환하지 못할 수도?
        - 최종 일관성: 갱신 결과가 결국 모든 사본에 반영(동기화)
    - 일관성 불일치 해소
        
        ### 비 일관성 해소 기법: 데이터 버저닝
        
        데이터 다중화 → 가용성 높아짐 → 사본 간의 일관성 깨질 확률도 높아짐 → 버저닝(versioning)과 벡터 시계 기술 사용하여 문제 해소
        
        - 버저닝: 데이터를 변경할 때마다 해당 데이터의 새로운 버전을 만드는 것
        - 벡터시계: [서버, 버전]의 순서쌍. 어떤 버전이 앞 버전인지, 다른 버전과 충돌이 있는지 판별하는데 쓰임
        - 어떻게 충돌이 일어났다는 것을 감지하는가???
            
            모든 구성요소의 값이 다른 버전 X에 포함된 모든 구성요소의 값보다 같거나 큰지만 보면된다.
            
        - 충돌이 일어나는 것을 알았다면, 어떻게 충돌을 해소하는가???
            
            **Last Write Wins (LWW) 방식 사용**
            
            - 데이터에 버전벡터와 함께 타임스탬프도 저장
            - gpt답변
                
                충돌이 발생한 데이터를 해결하는 방법 중 하나는 "최신 기록 우선 (Last Writer Wins)" 방식입니다. 이 방식은 각 데이터에 기록된 시간 정보를 확인하여 충돌이 발생한 경우, 더 최근에 기록된 데이터를 우선적으로 처리합니다.
                
                일반적으로 데이터는 타임스탬프(timestamp)라는 형태로 기록된 시간 정보를 가지고 있습니다. 충돌이 발생한 데이터들 중에서 타임스탬프가 더 최근인 데이터를 선택하여 처리합니다. 이는 가장 최근에 갱신된 데이터가 보다 정확한 정보를 담고 있다고 가정하는 방식입니다.
                
                예를 들어, A와 B 두 개의 프로세스가 동시에 데이터를 갱신하면서 충돌이 발생한 경우, 각 데이터의 타임스탬프를 비교하여 더 최근에 갱신된 데이터를 선택합니다. 이를 통해 충돌을 해결하고 일관성을 유지할 수 있습니다.
                
                하지만 "최신 기록 우선" 방식은 데이터 갱신의 순서에 따라 결과가 달라질 수 있는 상황을 야기할 수 있습니다. 동일한 데이터에 대해 동시에 여러 개의 갱신이 발생하면, 시스템에서는 임의로 하나의 갱신을 선택하여 적용하게 됩니다. 따라서, 이 방식을 사용할 때는 데이터 갱신의 순서에 따라 결과가 달라질 수 있다는 점을 유의해야 합니다.
                
                또한, "최신 기록 우선" 방식은 시간 정보를 기반으로 충돌을 해결하는 것이기 때문에 시계 동기화 문제에 영향을 받을 수 있습니다. 정확한 시간 동기화가 필요하며, 시계가 다르게 설정되어 있거나 네트워크 지연 등으로 인해 시간 동기화가 제대로 이루어지지 않으면 충돌 해결에 문제가 발생할 수 있습니다.
                
                따라서 "최신 기록 우선" 방식은 충돌 해결을 위한 일시적인 방법으로 사용되며, 실제 환경에서는 동시성 제어와 분산 시스템의 특정 요구사항에 맞는 다양한 충돌 해결 알고리즘을 고려해야 합니다.
                
        
        ### 단점
        
        - 클라이언트 구현 복잡해짐(왜 이게 단점???)
            1. 클라이언트 복잡성:  클라이언트 애플리케이션의 **복잡성을 증가시키고 개발 및 유지보수를 어렵게 만들 수 있습니다**. 또한, 클라이언트 측에서 충돌 감지와 해결을 처리하므로 **네트워크 대역폭을 소비하게 되어 성능에 영향**을 줄 수도 있습니다.
            2. 보안 문제: 충돌 감지와 해결 로직이 클라이언트에 노출되는 경우, 클라이언트 측에서 **해당 로직을 악용하거나 조작할 수 있는 보안 위협**이 될 수 있습니다. 해킹 시도나 악의적인 사용자가 충돌 감지 및 해결 로직을 우회하거나 변조할 수 있기 때문에, 이에 대한 추가적인 보호 메커니즘이 필요할 수 있습니다.
            3. 일관성 문제: 클라이언트는 독립적으로 동작하므로 네트워크 지연이나 다른 요인으로 인해 클라이언트들 사이에 상태 불일치가 발생할 수 있습니다. 이는 충돌 감지 및 해결 과정에서 문제를 일으킬 수 있고, 동기화 문제를 해결하기 위한 추가적인 조치가 필요할 수 있습니다
        - [서버:버전]의 순서쌍 개수가 굉장히 빨리 늘어남
            - 버전 벡터 노드 수가 늘어남에 따라 연산에 드는 비용도 늘어난다. 노드 수가 몇 만 이상이 되면 저장공간의 문제도 생긴다.
            - 임계치 설정하고 넘으면 오래된 순서쌍을 벡터 시계에서 제거
    - 장애 처리
        - 장애 감지 전략
            - 보통 두 대 이상의 서버가 서버A의 장애를 보고해야 장애가 발생했다고 간주
            1. 모든 노드 사이에 멀티캐스팅 채널 구축. But 서버 많으면 비효율적
            2. 가십 프로토콜
        - 장애 해소 전략
            1. 일시적 장애처리
                - 엄격한 정족수: 읽기 쓰기 연산 금지
                - 느슨한 정족수: 쓰기 연산 수행할 W개의 건강한 서버와 읽기 연산 수행할 R개의 건강한 서버를 해시 링에서 골라 가용성을 높임
                - 단서 후 임시 위탁(hinted handoff): 다른 서버가 잠시 맡아서 처리하고 복구되었을 때 일괄 반영
            2. 영구 장애 처리
                - 반-엔트로피(anti-entropy) 프로토콜
                - 머클 트리
            3. 데이터 센터 자앵 처리
                - 정전, 네트워크 장애, 자연재해 대비하자
                - 여러 데이터 센터에 다중화하자
            
    - 시스템 아키텍처 다이어그램
        1. 클라이언트는 get(key), put(ley, value)로만 통신
        2. 중재자는 프록시 역할 하는 노드
        3. 노드는 안정 해시의 해시링 위에 분포
        4. 노드를 자동으로 추가 및 삭제할 수 있도록 시스템 완전히 분산
        5. 데이터는 여러 노드에 다중화
        6. SPOF(Single Point of Failure)는 존재하지 않음
    - 쓰기 경로
        
        ![Untitled](6%E1%84%8C%E1%85%A1%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20%E1%84%82%E1%85%A9%E1%84%90%E1%85%B3%20adbfe6682f0042a99c74d7c6ea0d1b4d/Untitled%202.png)
        
        1. 쓰기 요청이 커밋 로그 파일에 기록된다.
        2. 데이터가 메모리 캐시에 기록된다.
        3. 메모리 캐시가 가득차거나 사전에 정의된 어떤 임계치에 도달하면 데이터는 디스크에 있는 SSTable에 기록된다. SSTable은 Sorted-String Table의 약어로, <키, 값>의 순서쌍을 정렬된 리스트 형태로 관리하는 테이블이다.
    - 읽기 경로
        1. 데이터가 메모리 캐시에 있으면 결과 바로 반환
        2. 없으면 디스크에서 가져와야함. → **블룸 필터(Bloom filter)** 사용
        - 블룸 필터
            
            [https://yujuwon.tistory.com/entry/BloomFilter를-이용해서-데이터-찾기](https://yujuwon.tistory.com/entry/BloomFilter%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%B4%EC%84%9C-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%B0%BE%EA%B8%B0)
            
            ![Untitled](6%E1%84%8C%E1%85%A1%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20%E1%84%82%E1%85%A9%E1%84%90%E1%85%B3%20adbfe6682f0042a99c74d7c6ea0d1b4d/Untitled%203.png)
            
            - 예제
                
                SSTable이 6개인 경우 블룸 필터의 동작 방식은 다음과 같습니다:
                
                1. 각 SSTable마다 독립적인 블룸 필터 생성: SSTable마다 해당하는 데이터를 담은 블룸 필터를 생성합니다. 이때, 각 SSTable의 크기와 데이터의 특성에 맞는 적절한 블룸 필터 크기와 해시 함수를 선택합니다.
                2. 데이터 저장 시 블룸 필터에 키 추가: SSTable에 데이터를 저장할 때, 해당 키를 각 SSTable에 해당하는 블룸 필터에 추가합니다. 키를 해시 함수에 적용하여 여러 개의 해시 값들을 얻고, 각 해시 값에 해당하는 블룸 필터의 비트 배열 위치를 1로 설정합니다.
                3. 데이터 조회 시 블룸 필터로 필터링: 데이터를 조회할 때, 먼저 블룸 필터를 사용하여 해당 키가 SSTable에 존재하는지 여부를 빠르게 확인합니다. 블룸 필터가 거짓 양성을 반환하지 않으면 키가 해당 SSTable에 존재할 가능성이 있는 것으로 간주합니다.
                4. 인덱스를 통한 위치 파악: 해당 키가 SSTable에 존재할 가능성이 있는 경우, 해당 SSTable의 인덱스를 검색하여 키의 위치 또는 범위를 파악합니다. 인덱스는 SSTable에 저장된 키의 정렬된 순서와 위치 정보를 가지고 있으며, 이를 통해 특정 키를 찾을 수 있습니다.
                5. 데이터 접근 또는 처리: 특정 키의 위치 또는 범위를 파악한 후, 해당 SSTable 파일에서 실제 데이터를 읽어오거나 처리합니다. 이를 통해 원하는 데이터에 접근하거나 작업을 수행할 수 있습니다.
                
                블룸 필터는 SSTable마다 독립적으로 사용되며, 데이터의 존재 여부를 빠르게 확인하기 위해 사용됩니다. 그러나 어느 SSTable에 키가 보관되어 있는지를 직접 알려주지는 않습니다. 해당 SSTable을 파악하기 위해서는 각 SSTable의 인덱스를 검색해야 합니다. 블룸 필터는 **빠른 필터링 기능을 제공**하여 **디스크 I/O를 줄이고 데이터 접근 속도를 향상**시키지만, 인덱스를 통해 SSTable의 위치를 알아야 실제 데이터에 접근할 수 있습니다.
                

---

### 요약

![Untitled](6%E1%84%8C%E1%85%A1%E1%86%BC%20%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5%20%E1%84%82%E1%85%A9%E1%84%90%E1%85%B3%20adbfe6682f0042a99c74d7c6ea0d1b4d/Untitled%204.png)